\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}         % Codificación UTF-8
\usepackage[T1]{fontenc}            % Soporte de caracteres especiales (ñ, acentos, etc.)
\usepackage[spanish]{babel}         % Traduce elementos automáticos al español
\usepackage{hyperref}               % Hipervínculos en el documento
\usepackage{amsmath}                % Mejoras en la escritura de fórmulas matemáticas
\usepackage{listings}               % Para insertar código fuente
\usepackage{xcolor}                 % Colores para el código
\usepackage{tocloft}                % Control sobre la tabla de contenidos
\usepackage{geometry}               % Configurar márgenes
\usepackage{enumitem}               % Mejor control de listas
\geometry{a4paper, margin=1in}

% Configuración para mostrar código Python
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegray},
    keywordstyle=\color{blue},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\footnotesize\ttfamily,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
\lstset{style=mystyle}

\title{Guía Detallada para Análisis de Datos con Python}
\author{Nombre del Investigador}
\date{\today}

\begin{document}

\maketitle

\tableofcontents
\newpage

\section{Introducción}
Esta guía tiene como objetivo explicar en detalle un análisis de datos realizado con Python, que utiliza técnicas de machine learning y visualización para analizar datos de ventas de videojuegos. Se asume que el lector no tiene experiencia previa en programación, por lo que se explicarán cada uno de los conceptos y pasos de forma detallada.

\subsection{Objetivos}
\begin{itemize}
    \item Explicar la estructura y propósito del código.
    \item Describir cada sección y función utilizada en el análisis.
    \item Proveer un glosario de términos técnicos.
\end{itemize}

\section{Requisitos y Configuración del Entorno}
Para ejecutar el código de análisis es necesario contar con Python instalado y disponer de las siguientes librerías:
\begin{itemize}
    \item \textbf{pandas}: Manipulación y análisis de datos.
    \item \textbf{numpy}: Cálculos numéricos.
    \item \textbf{seaborn}: Visualización de datos avanzada.
    \item \textbf{matplotlib}: Creación de gráficos.
    \item \textbf{scikit-learn}: Implementación de modelos de machine learning.
\end{itemize}

\subsection{Instalación de las Librerías}
En un Jupyter Notebook, puedes instalar las librerías necesarias ejecutando la siguiente celda:

\begin{lstlisting}[language=bash]
!pip install pandas numpy seaborn matplotlib scikit-learn
\end{lstlisting}

Si usas \textbf{Anaconda}, puedes instalarlas con:
\begin{lstlisting}[language=bash]
!conda install pandas numpy seaborn matplotlib scikit-learn -y
\end{lstlisting}

\section{Explicación del Código}
A continuación se presenta el código utilizado para el análisis y se explica cada parte en detalle.

\subsection{1. Cargar Datos}
\begin{lstlisting}[language=Python]
import pandas as pd

# Cargar datos desde un archivo CSV.
df = pd.read_csv("prueba.csv", delimiter=';', encoding="utf-8")
\end{lstlisting}
\textbf{Explicación:}  
Se importa la librería \textbf{pandas} y se carga un archivo CSV llamado \texttt{prueba.csv}. Se usa el delimitador \texttt{';'} y la codificación \texttt{utf-8} para asegurar que los caracteres especiales se lean correctamente. Si encuentras problemas con caracteres como la "ñ", asegúrate de tener configurado \texttt{[utf8]} en \texttt{inputenc} y \texttt{T1} en \texttt{fontenc}.

\subsection{2. Preprocesamiento de Datos}
\begin{lstlisting}[language=Python]
# Eliminar filas con valores nulos
df.dropna(inplace=True)

# Codificar variables categoricas
from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
df['Plataforma'] = encoder.fit_transform(df['Plataforma'])
df['Genero'] = encoder.fit_transform(df['Genero'])
df['Editorial'] = encoder.fit_transform(df['Editorial'])
\end{lstlisting}
\textbf{Explicación:}  
Se eliminan las filas con datos faltantes usando \texttt{dropna()}. Luego, se convierten las variables categóricas (como Plataforma, Género y Editorial) en valores numéricos utilizando \textbf{LabelEncoder} de \texttt{scikit-learn}. Esto es fundamental para que los algoritmos de machine learning puedan procesar los datos.

\subsection{3. Definir Variables Predictoras y Objetivo}
\begin{lstlisting}[language=Python]
# Variables predictoras (features) y la variable objetivo (target)
X = df[['Plataforma', 'Anio', 'Genero', 'Editorial', 'Ventas NA', 'Ventas EU', 'Ventas JP', 'Ventas Otros']]
y = df['Ventas Global']
\end{lstlisting}
\textbf{Explicación:}  
Se seleccionan las columnas que se usarán para predecir las ventas globales. Las columnas en \texttt{X} contienen la información explicativa, mientras que \texttt{y} es la variable que deseamos predecir.

\subsection{4. División de Datos en Entrenamiento y Prueba}
\begin{lstlisting}[language=Python]
from sklearn.model_selection import train_test_split

# Division de datos: 80\% para entrenamiento y 20\% para prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
\end{lstlisting}
\textbf{Explicación:}  
Se utiliza la función \textbf{train\_test\_split} para dividir los datos en dos conjuntos: uno para entrenar el modelo y otro para evaluar su desempeño. Esto ayuda a prevenir sobreajuste y medir la capacidad predictiva del modelo.

\subsection{5. Modelo de Predicción}
\begin{lstlisting}[language=Python]
from sklearn.ensemble import RandomForestRegressor

# Crear y entrenar el modelo de regresion (Random Forest)
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Realizar predicciones sobre los datos de prueba
y_pred = model.predict(X_test)
\end{lstlisting}
\textbf{Explicación:}  
Se emplea el algoritmo \textbf{Random Forest Regressor} para predecir las ventas globales. Este algoritmo crea múltiples árboles de decisión y combina sus resultados para obtener una predicción más robusta. El parámetro \texttt{n\_estimators=100} indica que se utilizarán 100 árboles, y \texttt{random\_state=42} garantiza la reproducibilidad.

\subsection{6. Evaluación del Modelo}
\begin{lstlisting}[language=Python]
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Evaluacion del modelo: calculo de metricas
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f"MAE: {mae}, MSE: {mse}, R2: {r2}")
\end{lstlisting}
\textbf{Explicación:}  
Se calculan tres métricas para evaluar la precisión del modelo:
\begin{itemize}
    \item \textbf{MAE (Error Absoluto Medio):} Promedio de las diferencias absolutas entre los valores predichos y los reales.
    \item \textbf{MSE (Error Cuadrático Medio):} Promedio de los errores al cuadrado.
    \item \textbf{R2:} Coeficiente de determinación que indica qué proporción de la varianza se explica con el modelo.
\end{itemize}

\subsection{7. Análisis de Tendencias}
\begin{lstlisting}[language=Python]
import seaborn as sns
import matplotlib.pyplot as plt

# Grafico de la tendencia de ventas globales a lo largo de los anios
plt.figure(figsize=(12, 6))
sns.lineplot(data=df, x='Anio', y='Ventas Global', ci=None)
plt.title("Tendencia de ventas globales a lo largo de los anios")
plt.xlabel("anios")
plt.ylabel("Ventas Globales (millones)")
plt.show()
\end{lstlisting}
\textbf{Explicación:}  
Se genera un gráfico de línea para visualizar cómo han evolucionado las ventas globales a lo largo de los años. Esto permite identificar tendencias temporales y patrones de comportamiento en los datos.

\subsection{8. Comparación de Plataformas y Géneros}
\begin{lstlisting}[language=Python]
# Grafico de caja para comparar ventas por plataforma
plt.figure(figsize=(12, 6))
sns.boxplot(data=df, x='Plataforma', y='Ventas Global')
plt.xticks(rotation=90)
plt.title("Distribucion de ventas por plataforma")
plt.show()

# Grafico de caja para comparar ventas por genero
plt.figure(figsize=(12, 6))
sns.boxplot(data=df, x='Genero', y='Ventas Global')
plt.xticks(rotation=90)
plt.title("Distribucion de ventas por genero")
plt.show()
\end{lstlisting}
\textbf{Explicación:}  
Se crean dos gráficos de caja (\textbf{boxplots}) para comparar la distribución de las ventas globales según la plataforma y el género del videojuego. Estos gráficos ayudan a identificar variaciones, dispersiones y posibles valores atípicos (outliers).

\section{Glosario de Términos}
\begin{description}[style=nextline]
    \item[DataFrame:] Estructura de datos bidimensional que se utiliza en \textbf{pandas} para almacenar datos en forma de tabla.
    \item[Machine Learning:] Campo de la informática que se centra en que las computadoras aprendan a partir de datos sin ser explícitamente programadas para ello.
    \item[Random Forest:] Algoritmo de machine learning que utiliza múltiples árboles de decisión para mejorar la precisión y evitar el sobreajuste.
    \item[Encoding:] Proceso de transformar datos categóricos (como texto) en valores numéricos.
    \item[Train-Test Split:] Técnica que consiste en dividir el conjunto de datos en dos partes: una para entrenar el modelo y otra para evaluarlo.
    \item[Métricas de Evaluación:] Medidas utilizadas para cuantificar el rendimiento de un modelo, por ejemplo, MAE, MSE y R2.
    \item[LabelEncoder:] Herramienta de scikit-learn que convierte variables categóricas en números.
\end{description}

\section{Consideraciones Especiales}
\begin{itemize}
    \item \textbf{Codificación de Caracteres:} Si se presentan problemas con caracteres especiales (como la "ñ" o acentos), asegúrate de que el archivo CSV esté guardado en \texttt{utf-8} y que el documento LaTeX utilice los paquetes \texttt{inputenc} y \texttt{fontenc} correctamente configurados.
    \item \textbf{Reinicio del Kernel:} Tras instalar nuevas librerías en Jupyter Notebook, es recomendable reiniciar el kernel para evitar conflictos.
\end{itemize}

\section{Conclusión}
Esta guía detalla paso a paso el proceso de análisis de datos aplicado a un conjunto de datos de ventas de videojuegos. Se ha explicado desde la carga y preprocesamiento de los datos, la aplicación de un modelo de machine learning con Random Forest, hasta la visualización y análisis de tendencias. El enfoque modular y el glosario permiten a principiantes comprender y aplicar técnicas complejas de análisis.

\end{document}
